{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from helper import *\n",
    "import csv  \n",
    "from io import BytesIO\n",
    "from IPython import display\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"../guppies-test-4c48569421d8.json\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all files from the google bucket. Can cycle through the files in this list and write results to the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all JPG files. All images are in both .jpg and .nef formats, need to avoid duplicates.\n",
    "all_files = ListAvaliableFiles(\"guppy_images\")\n",
    "all_jpg_files = [ x for x in all_files if \"JPG\" in x ]\n",
    "\n",
    "# Read the random number array we will use to assign images.\n",
    "# random_array = np.arange(len(all_jpg_files))\n",
    "# np.random.shuffle(random_array)\n",
    "# np.save('../Data/radom_array.npy', random_array)\n",
    "random_array = np.load('../Data/radom_array.npy')\n",
    "\n",
    "# Assign images.\n",
    "Jordan_array = random_array[0:500]\n",
    "Sunny_array = random_array[500:1000]\n",
    "\n",
    "Jordan_files = []\n",
    "Sunny_files = []\n",
    "\n",
    "for index in Jordan_array:\n",
    "    Jordan_files.append(all_jpg_files[index])\n",
    "\n",
    "for index in Sunny_array:\n",
    "    Sunny_files.append(all_jpg_files[index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opens a file from the google bucket (or locally, depends if using RetreiveImage (cloud) or LoadImage (local)), crops it, reads it and corrects the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Retreive cloud image\"\"\"\n",
    "# file = all_jpg_files[50]\n",
    "file= '1301/Lower Lalaja/28A/100NCD60/DSC_1728.JPG'\n",
    "image = RetreiveImage(file, verbose=True)\n",
    "\n",
    "\"\"\"Read local image\"\"\"\n",
    "# file = '/Users/jordan/Desktop/Guppies/Data/raw/DSC_1053.JPG'\n",
    "# image = LoadImage(file)\n",
    "\n",
    "cropped_image = CroppedImage(image, verbose=True)\n",
    "output_string, word_confidences = ReadImage(cropped_image, verbose=True)\n",
    "label = FindErrors(output_string, verbose=True)\n",
    "print(\"Initial label:\", output_string,\n",
    "      \"\\nCorrected label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write filename, initial prediction, corrected prediction and the manually inputted truth to the truth.csv file for a set of file names.\n",
    "The files have been randomised and split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/truth.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for file in Sunny_files:\n",
    "        # Read the data and predict the label.\n",
    "        image = RetreiveImage(file, verbose=False)\n",
    "        cropped_image = CroppedImage(image, verbose=False)\n",
    "\n",
    "        display.display(Image.open(cropped_image))\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        initial_prediction = ReadImage(cropped_image, verbose=False)[0]\n",
    "        corrected_prediction = FindErrors(initial_prediction)\n",
    "    \n",
    "        # Provide truth\n",
    "        truth = input(\"Truth:\")\n",
    "\n",
    "        writer.writerow([file, initial_prediction, corrected_prediction, truth])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read through all cloud files and write filename, initial prediction and corrected prediction to the predictions.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = all_jpg_files\n",
    "with open('../Data/predictions.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(['filename', 'prediction', 'corrected'])\n",
    "\n",
    "    for i, file in enumerate(files):    \n",
    "        print(f'{i+1}/{len(files)}',end='\\r')\n",
    "\n",
    "        # Read the data\n",
    "        image = RetreiveImage(file, verbose=False)\n",
    "        cropped_image = CroppedImage(image, verbose=False)\n",
    "        Image.open(cropped_image)\n",
    "        initial_prediction = ReadImage(cropped_image, verbose=False)[0]\n",
    "        corrected_prediction = FindErrors(initial_prediction)\n",
    "        \n",
    "        # write the data\n",
    "        writer.writerow([all_files[i], initial_prediction, corrected_prediction])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some code to reanalyse predictions once we have changed the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "pred_file = 'Truth'\n",
    "\n",
    "with open(f'../Data/{pred_file}_new.csv', 'w') as f_new:\n",
    "    with open(f'../Data/{pred_file}.csv', 'r') as f:\n",
    "        filereader = csv.reader(f)\n",
    "        writer = csv.writer(f_new)\n",
    "        for n, row in enumerate(filereader):\n",
    "            if row != []:\n",
    "                new_row = row[:2]\n",
    "\n",
    "                new_prediction = FindErrors(row[1])\n",
    "\n",
    "                new_row.append(new_prediction)\n",
    "                new_row.append(row[3])\n",
    "\n",
    "                writer.writerow(new_row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now delete old file and rename new one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some code to check the accuracy of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "correct_files = []\n",
    "incorrect_files = []\n",
    "invalid_files = []\n",
    "\n",
    "character_confusions = []\n",
    "\n",
    "\n",
    "with open(f'../Data/{pred_file}_new.csv', 'r') as f:\n",
    "    filereader = csv.reader(f)\n",
    "    for n, row in enumerate(filereader):\n",
    "        if row != []:\n",
    "            correct = int(row[3] == row[2])\n",
    "            if correct:\n",
    "                correct_files.append(row[0])\n",
    "\n",
    "            if not correct:\n",
    "                if row[2] == '1':\n",
    "                    invalid_files.append(row[0])\n",
    "                    print(n + 1, \"Invalid\")\n",
    "\n",
    "                else: \n",
    "                    true = row[3].split('-')\n",
    "                    pred = row[2].split('-')\n",
    "\n",
    "                    incorrect_files.append(row[0])\n",
    "\n",
    "                    if len(true) != 3 or len(pred) != 3:\n",
    "                        print(n, 'error')\n",
    "                        continue\n",
    "\n",
    "                    for i in range(3):\n",
    "                        if true[i] != pred[i]:\n",
    "                            print(n + 1, true[i], pred[i])\n",
    "\n",
    "                            if (i == 1) and (len(true[i]) == len(pred[i])): #mistake in identity.\n",
    "                                for j in range(len(true[i])):\n",
    "                                    if true[i][j] != pred[i][j]:\n",
    "                                        character_confusions.append((true[i][j], pred[i][j]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nNumber Correct:\", len(correct_files), \n",
    "      \"\\nNumber Incorrect:\", len(incorrect_files),\n",
    "      \"\\nNumber Invalid:\", len(invalid_files))\n",
    "\n",
    "character_confusions =np.array(character_confusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attempted % Correct:\", len(correct_files) / (len(correct_files) + len(incorrect_files)))\n",
    "print(\"Total % Correct:\", len(correct_files) / (len(correct_files) + len(incorrect_files) + len(invalid_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Data/incorrect_files.npy',np.array(incorrect_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_chars = [X[0] for X in character_confusions]\n",
    "true_chars_unique = np.unique(true_chars)\n",
    "pred_chars = [X[1] for X in character_confusions]\n",
    "pred_chars_unique = np.unique(pred_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix =  np.zeros((len(true_chars_unique), len(pred_chars_unique)))\n",
    "\n",
    "for i in range(len(true_chars_unique)):\n",
    "    for j in range(len(pred_chars_unique)):\n",
    "        confusion_matrix[i,j] = np.sum((character_confusions[:,0] == true_chars_unique[i]) & (character_confusions[:,1] == pred_chars_unique[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Confusion Matrix. This can be read by the code to directy choose the appropraite replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_data = [confusion_matrix, true_chars_unique, pred_chars_unique]\n",
    "np.save('../Data/ConfusionData/confusion_matrix.npy', confusion_data[0])\n",
    "np.save('../Data/ConfusionData/confusion_true_chars.npy', confusion_data[1])\n",
    "np.save('../Data/ConfusionData/confusion_pred_chars.npy', confusion_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixPath = '../Data/ConfusionData'\n",
    "\n",
    "confusion_matrix = np.load(ConfusionMatrixPath + '/confusion_matrix.npy')\n",
    "true_chars_unique = np.load(ConfusionMatrixPath + '/confusion_true_chars.npy')\n",
    "pred_chars_unique = np.load(ConfusionMatrixPath + '/confusion_pred_chars.npy')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(confusion_matrix)\n",
    "plt.yticks(np.arange(len(true_chars_unique)), true_chars_unique)\n",
    "plt.xticks(np.arange(len(pred_chars_unique)), pred_chars_unique)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted Character\")\n",
    "plt.ylabel(\"True Character\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reads image from error file array in full verbose mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = invalid_files\n",
    "\n",
    "file = files[5]\n",
    "image = RetreiveImage(file, verbose=True)\n",
    "\n",
    "cropped_image = CroppedImage(image, verbose=True)\n",
    "output_string, word_confidences = ReadImage(cropped_image, verbose=True)\n",
    "label = FindErrors(output_string, verbose=True)\n",
    "print(\"Initial label:\", output_string,\n",
    "      \"\\nCorrected label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code used to combine truth_sunny and truth_Jordan files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = ['../Data/truth_Jordan.csv', '../Data/truth_sunny.csv']\n",
    "\n",
    "# whole_file = []\n",
    "\n",
    "# for file in files:\n",
    "#     with open(file, 'r') as f:\n",
    "#         filereader = csv.reader(f)\n",
    "#         for row in filereader:\n",
    "#             if row != []:\n",
    "#                 whole_file.append(row)\n",
    "\n",
    "\n",
    "# with open('../Data/Truth.csv', 'w') as Truth:\n",
    "#     writer = csv.writer(Truth)\n",
    "#     for row in whole_file:\n",
    "#         writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code used to download all incorrect images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "truth_path = '../Data/Truth_new.csv'\n",
    "\n",
    "error_files = ErrorFiles(truth_path)[0]\n",
    "correct_files = ErrorFiles(truth_path)[2]\n",
    "random.shuffle(correct_files)\n",
    "correct_subset = correct_files[0:200]\n",
    "\n",
    "for i, file in enumerate(error_files):\n",
    "    # Initialise a client\n",
    "    storage_client = storage.Client()\n",
    "    # Create a bucket object for our bucket\n",
    "    bucket = storage_client.get_bucket(\"guppy_images\")\n",
    "    # Create a blob object from the filepath\n",
    "    blob = bucket.blob(file)\n",
    "    # Download the file to a destination\n",
    "    blob.download_to_filename('../Data/ErrorImages/%s' %(file.replace(\"/\", \"-\")))\n",
    "    print(\"%i/%i\" %(i+1, len(error_files)))\n",
    "\n",
    "for i, file in enumerate(correct_subset):\n",
    "    # Initialise a client\n",
    "    storage_client = storage.Client()\n",
    "    # Create a bucket object for our bucket\n",
    "    bucket = storage_client.get_bucket(\"guppy_images\")\n",
    "    # Create a blob object from the filepath\n",
    "    blob = bucket.blob(file)\n",
    "    # Download the file to a destination\n",
    "    blob.download_to_filename('../Data/CorrectImages/%s' %(file.replace(\"/\", \"-\")))\n",
    "    print(\"%i/%i\" %(i+1, len(correct_subset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../Data/{pred_file}_new.csv', 'r') as f:\n",
    "    filereader = csv.reader(f)\n",
    "    for n, row in enumerate(filereader):\n",
    "        split = row[3].split('-')[1]\n",
    "        if '0' in split:\n",
    "            print(split, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
